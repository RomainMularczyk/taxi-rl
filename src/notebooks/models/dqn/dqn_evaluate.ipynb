{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5b15d3-b35b-461f-ace0-6b4fdd596b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 06:15:30 [INFO] Logger initialized with level INFO.\n"
     ]
    }
   ],
   "source": [
    "import os; os.chdir(\"../../..\")\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from torch import nn\n",
    "from lib.formulas.deep_q_learning import DeepQLearning\n",
    "from lib.policies.EpsilonDQNPolicy import EpsilonDQNPolicy\n",
    "from lib.policies.DQNPolicy import DQNPolicy\n",
    "from lib.policies.RandomSamplePolicy import RandomSamplePolicy\n",
    "from lib.data.neural_network import Model\n",
    "from lib.evals.models.metrics import graph_training_evolution, aggregate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bae19be-7190-4522-9a4f-8c123081011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = Model(500, 6, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f009d83-1208-43d6-bf4e-0feda7da78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\")\n",
    "policy = EpsilonDQNPolicy(\n",
    "    game_env=env,\n",
    "    epsilon=0.9,\n",
    "    decay_rate=0.05,\n",
    "    policy_network=policy_net,\n",
    "    legal=True,\n",
    ")\n",
    "dqn = DeepQLearning(\n",
    "    policy=policy,\n",
    "    gamma=0.9,\n",
    "    tau=0.8,\n",
    "    batch_size=16,\n",
    "    sample_depth=200,\n",
    "    loss_function=nn.HuberLoss(),\n",
    "    optimizer=torch.optim.Adam(policy_net.parameters(), lr=0.01, amsgrad=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c4ab9e-d7c9-4961-a84d-fc50ecb95f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [05:22<00:00,  1.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-227.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1928.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1928.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1901.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1928.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1901.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1892.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1928.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1955.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1964.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-227.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1883.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1955.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1973.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1919.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1937.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1919.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1955.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-245.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1964.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1955.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1919.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1955.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1946.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1973.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-209.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1928.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1937.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-218.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1919.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-1937.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-236.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0),\n",
       " EpisodeMetrics(steps=200, cumulative_reward=-200.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f395d0-048b-4d63-8bea-b0ad9968f912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aaa1c-4e19-4c2a-aefe-45cc4a0665ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
